{% extends "main_template.html" %}

{% set title = "Work" %}
{% set current_nav = "work" %}

<!-- Body -->
{% block content %}
<div class="section">

  <div style="text-align: center;">
    <h2>Work</h2>
  </div>

  <h3>Google<span style="font-weight:normal">(2018 - Present)</span></h3>

  I work on the Location Platform as part of Google Maps, where I leverage data engineering and machine learning to make Google Maps smarter, more personalized, and more magical.
  
  <h3>LendUp<span style="font-weight:normal">(2013 - 2018)</span></h3>

  LendUp is a startup whose goal is to safely offer credit all who need it.
  We offer credit cards, installment loans, and single payment loans to those who qualify.
  I began work at the company in early 2013 as the Head of Risk and Analytics (I was the 11th employee at the company).
  My role was to design and implement our risk and underwriting program, which entailed
  collecting and processing datasets, designing and testing statistical models for estimating credit risk,
  and writing software to serve our models in production and to score them in applicants.
  I grew the team from just myself into fully staffed Data Science, Data Engineering, and Credit teams.
  As the team grew, I as an individual contributor focused on building our statistical models and designing the data pipelines and tools required to maintain them.

  <h3>CERN / ATLAS <span style="font-weight:normal">(2007 - 2013)</span></h3>

  I earned my PhD at New York University where I worked on the ATLAS experiment,
  which is one of the two major experiments at the Large Hadron Collider (LHC).
  My research focused on performing precision measurements of the properties of Top Quarks,
  and in particular using advanced statistical techniques and technologies to
  build sophisticated models to describe our data and achieve more accurate results.
  In addition, I was the primary maintainer and developer of a statistical modeling package
  written in C++.  Our framework made it easy for other researchers to build
  large, detailed models and to leverage modern inference techniques.
  And, as a member of the collaboration, I wrote software in C++ to identify collisions
  worthy of beineg saved and further resarched, which ran in production on the 10s of millions of events per second that the LHC produced.
  For a discussion of my research results, see <a href="/atlas">HERE</a>.

  <h3>Portfolio</h3>

  Here is a collection of sample and side projects:

  <ul>

    <li> <b><a href="https://github.com/ghl3/SpontaneousSymmetry">Spontaneous Symmetry</a></b>: This very site, written in Flask and served on AWS using nginx and docker.</li>
    <br>

    <li> <b><a href="/stats">Statistics:</a></b> An introduction to statistics and inference.</li>
    <br>

    <li> <b><a href="https://github.com/ghl3/higgs-kaggle">Higgs
    Kaggle</a></b>: My solution to the <a href="https://www.kaggle.com/c/higgs-boson">higgs boson Kaggle competition</a>.</li>
    <br>

    <li> <b><a href="https://github.com/ghl3/gtrees">gTrees</a></b>: Python and Cython module for building and fitting decision trees using genetic algorithms to optimize arbitrary loss functions.</li>
    <br>

    <li> <b><a href="blog/2017-11-05-alpha-four">AlphaFour</a></b>: An AI for the game ConnectFour, inspired by AlphaGo and built in tensorFlow.</li>
    <br>

    <li> <b><a href="https://github.com/ghl3/dataframe">dataframe</a></b>: Dataframes for Clojure (inspired by python's Pandas)</li>
    <br>

    <li> <b><a href="https://github.com/ghl3/jest">Jest</a></b>: A functional programming language for the JVM.</li>
    <br>

    <li> <b><a href="https://github.com/ghl3/bamboo">Bamboo</a></b>: A
    set of helper functions for plotting and data manipulation using
    python and Pandas.</li>
    <br>
</ul>

  <h3> Resume </h3>

  A copy of my resume can be obtained <a href="https://github.com/ghl3/resume/raw/master/resume.pdf">HERE</a>.

{% endblock %}

{% block sidebar %}
{% endblock %}
