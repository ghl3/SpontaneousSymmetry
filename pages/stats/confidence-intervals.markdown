---
author: 
date: 2016-09-03 11:25:54.397075
layout: post
slug: confidence-intervals
title: Confidence Intervals
---


# Confidence Intervals

We previously discussed the concept of estimators as a way to find a value that approximates an unknown parameter.  A drawback of using an estimator is that it doesn't provide a level of uncertainty on the estimate.  A more general way to estimate the value of a parameter is by calculating a "confidence interval".  

A confidence interval answers the question: "For a given measured dataset, what is the set of points of the parameter which are supported by the data (or, conversely, which points are rejected by the data)?"  It does this in a mathematically rigorous, but somewhat confusing way.  It's worth pointing out that a confidence interval is only a single example of one thing that a person *could* do when attempting to estimate a parameter.  It is a procedure, motivate by statistical intuition, that can be a useful took when thinking about a problem or making a decision.  But how one chooses to use data or what one wants to calculate all depend on one's purposes, the level of rigor necessary, and one's philosophy.  For now, let's assume that calculating a confidence interval is what we'd like to do here.


## Definition

Formally, a confidence interval is a procedure for calculating an interval in parameter space based on observed data that has a fixed probability of containing the "true" value of the parameter.  It is important to note that the interval is based on the data, meaning that the interval itself is a random variable (different data draws will produce different intervals).  In a frequentist framework, the true value of a parameter is NOT a random variable: it is some fixed (but unknown) value.  Therefore, a frequentist does not talk about the probability that the true value is in some fixed interval.  Instead, they talk about the probability that an interval contains the true value.  For any fixed interval, it either DOES contain the true value or DOES NOT.

The probability that the confidence interval contains the true value of the parameter of interest is known as the "size" of the interval, and is usually chosen in advance of calculating the interval.  For example, a 95% confidence interval will contain the true value of a parameter 95% of the time (depending on what observed data is generated by the model).

It isn't immediately clear how to translate the definition of a confidence interval into an actual calculation.  The definition is more of a description of the properties that an interval must have and not a prescription of how to create an interval with such properties.  Let's walk through how to actually translate this description into an actual interval.


## Neyman Construction

Calculating a confidence interval means coming up with a procedure that will generate an interval which contains the true value of the parameter of interest some pre-determined percentage of the time.  The trouble is that, since we don't KNOW that true value, we must ensure our procedure works for ALL possible values of the parameter, knowing that ANY of them could be the true value.  That's the challenge of a confidence interval.  While this seems initially foreboding, it turns out that it can be calculated using a relatively simple method which creates intervals having this property "by construction".

Let's assume we're working in the simple case where we have a single parameter $\theta$ described by a probability distribution function $p$:

$$
p = p(x | \theta)
$$

The data $x$ may be multi-dimensional.  However, we are free to choose a function of the data (and possibly the parameter of interest) whose value is 1 dimensional.  This is known as a test statistic: $t = t(\vec{x}, \theta)$ with $t \in \mathbb{R}$.  We note that the test statistic may be defined in terms of the value of the parameter of interest for a hypothetical model.  We will discuss the details of test statistics and how to choose a "good" test statistic later.

The procedure for producing a confidence interval is the following:

- Choose a "test statistic" $t(x)$
- For each possible value of the parameter $\theta$, determine the distribution of the test statistic: $p(t(x, \theta) | \theta)$.
- For every value of $\theta$, using the distributions above, choose a window in the domain of the data ($t \in [a, b]$) such that the total probability of that window is the size of the confidence window: $\int_a^b p(t | \theta) dt = \alpha$.  Record these windows $[a(\theta), b(\theta)]$ for each value of $\theta$.
- Measure the data $x$ and calculate the measured value of the test statistic $t_0 = t(x)$
- Find all values of the parameter $\theta$ such that $t_0$ falls in the windows $[a(\theta), b(\theta)]$ that we chose above.  In other words, determine the set $\{\theta : a(\theta) < t_0 < b(\theta)\}$.
- This set of values of $\theta$ forms the confidence interval on the parameter $\theta$ of size $\alpha$.


<!--
To me, the simplest way to calculate a confidence interval is using what I'll call the "brute force" method.  This method relies on generating many possible datasets for many possible values of the parameter of interest, which will be used to infer the distribution of our data for every possible parameter value (or as many as we need to satisfy our desired level of exactness).  We will first describe this procedure and then discuss why it creates confidence intervals (as defined above).

Let's label our data as $x$ and our single parameter as $\theta$, and assume that we want to generate a confidence interval of size $\alpha$.  Given that, the brute force procedure is as follows:


- For each value of our parameter $\theta$, generate many datasets.  For each value of $\theta $ , using the generated data, create a distribution $p(x | \theta)$ 

- For every value of $\theta$, choose a window in the domain of the data ($x \in [a, b]$) such that the total probability of that window is the size of the confidence window: $\int_a^b p(x | \theta) dx = \alpha$.  Record these windows $[a(\theta), b(\theta)]$ for each value of $\theta$.
- Run the experiment and measure the observed value of x
- Given that measured data, find all values of the parameter $\theta$ such that x falls in the window created above.  In other words, determine the set $\{\theta : a(\theta) < x < b(\theta)\}$.
- That set of values of $\theta$ forms the confidence interval on the parameter $\theta$ of size $\alpha$.
-->

This procedure is known as the Neyman Construction.  The set of all points that fall in the union of each window $[a(\theta), b(\theta)]$ for all values of the parameter $\theta$ is sometimes called the Confidence Band, as it traces out a 2-d sheet in parameter/data space.
   
Why does an interval, defined in this way, have the properties of the confidence interval that we desire (namely that it contains the true value of $\theta$ with probability $\alpha$)?  Well, we start with the fact that there is only one TRUE value of $\theta$: $\theta_{true}$, which is of course unknown to the person performing the experiment.  Given that fixed value of $\theta_{true}$, there is a true distribution of t: $p(t) = p(t | \theta_{true})$. <!--there will be a distribution of $\t$ generated (and we will measure a single random variable from that distribution when we perform the experiment).  -->  In our procedure to generate confidence intervals, we picked windows $[a(\theta), b(\theta)]$ for all possible values of $\theta$ where the probability of t falling into that window is exactly $\alpha$.  In particular, this is true of $\theta_{true}$.

The key point is that the set $\{\theta : a(\theta) < t_0 < b(\theta)\}$ will contain  $\theta_{true}$ if and only if the measured value $t_0$ falls between $[a(\theta_{true}), b(\theta_{true})]$.  But, by construction, $t_0$ falls into this window $\alpha$ of the time (because we defined the window to have total probability of t equal to $\alpha$).  Therefore, the confidence interval defined by $\{\theta : a(\theta) < t_0 < b(\theta)\}$ will contain the true value of the parameter $\theta_{true}$ a fraction of the time equal to $\alpha$.  This is the property that we are looking to show, which proves that our procedure produces confidence intervals.

<!--
To summarize, there are two possible cases that can take place:

- Case 1: Given $\theta_{\text{true}}$, the value of $t_0$ that we draw **IS** in that window.  In this case, when the experimenter builds their confidence interval as described above, it will contain the true value of $\theta$, since $\theta_{\text{true}}$ will be one of the $\theta$ values whose confidence interval of size $\alpha$ contains $t_0$
- Case 2: Given $\theta_{\text{true}}$, the value of $t$ that we draw **IS NOT** in that window.  Therefore, by the same logic, the experimenter's confidence interval will NOT contain the true value of $\theta$, since the measured value of $t_0$ is outside of the confidence interval of size $\alpha$.
-->


<!--
And, as described, we know that case 1 occurs 95% of the time and case 2 5% of the time.  Therefore, we have proven that a confidence interval, as described above, will have the properties that we desire.
-->

There is one loose end remaining.  When picking the window $[a, b]$ for a given value of $\theta$ (knowing the distribution $p(t | \theta)$), we required that it must have a total probability of $\alpha$.  However, there are many windows $[a, b]$ that contain that total probability (infinitely many for a continuous parameter).  Any choice of values of $[a, b]$ will create confidence intervals, as our proof above didn't depend on any particular choice of $[a, b]$.  So, would could then wonder, given a distribution, what particular range of $[a, b]$ should one choose (given that it must contain a total probability of $\alpha$)?

To help inform the answer, recall that the goal of a confidence interval is to give bounds that are useful in considering the true value of a parameter.  Intuitively, the smaller those bounds are, the more useful they are in constraining that parameter.  Therefore, one possible way of determining which intervals are valuable are those that are smallest.  It is relatively straight-forward to show that those intervals which contain the highest values of $p(t | \theta)$ will be the shortest (the higher the values of $p(t | \theta)$ you choose, the fewer values of $\theta$ you must integrate over to obtain $\int_a^b p(t | \theta) dt = \alpha$).  As an alternative, one may choose to pick intervals that are symmetric around some value (though, this will not be possible in general).  One may also choose to start from $-\infty$ until the distribution integrates to $\alpha$.  There are many choices, and any particular choice should be considered in the context of the problem you are solving or the type of statistical statement you are trying to make.  The choice that one makes here is known as an "ordering rule", since it determines the order you move in through the space of data while accumulating points to determine the interval $[a, b]$.  And difference choices will produce different confidence intervals that have different properties.  We will discuss the details of this later.


The Neyman Procedure, as described above, is in many ways an extension of the Neyman-Pearson procedure of solving the Simple Hypothesis problem, as described above.  One can define similar properties to confidence intervals as on can to hypothesis tests:

- A "Type 1" error in the context of a confidence interval is when the confidence interval does not contain the true parameter.  From the definition of the confidence interval, it follows that the probability of a "Type 1" error is the "size" of the confidence interval, or $\alpha$.
- Power, however, doesn't have a direct analog in the context of Confidence Intervals, unless one fully specifies how a confidence interval is to be used to perform a hypothesis test.  This is because there is no single alternate hypothesis, but many different alternate models (one for every possible value of our parameter, $\theta$).  Any confidence interval will contain an infinite number of parameter values $\theta$ that are not equal to $\theta_{\text{true}}$.  So, in one sense, every confidence interval makes a "Type 2" error by including incorrect parameter values.  But, intuitively, confidence intervals that are thinner for many possible values of $\theta_{\text{true}}$ are "better", and one can interpret size of the confidence interval as a loose analogy to "power".


Continuing with comparison to hypothesis tests, one can interpret the Neyman procedure for producing confidence intervals as finding the set of all parameter points that are not rejected when performing a p-value test on the model associated with that parameter point (given the observed data).  In this sense, a confidence interval can be thought of as an "inverted hypothesis test". <!-- The hypothesis test for a given parameter point is "2-sided", as we're open to more extreme values in either direction.  (For a 2-sided test, there is no "uniformly most powerful" test https://indico.cern.ch/event/117033/contributions/1327622/attachments/55727/80175/Cranmer_L3.pdf)
-->

Let's show that this gives us the same procedure as described above.  Imagine that we measure a value of our data $t_0$ and we want to perform a p-value test on the model defined by $\theta$ using a threshold of $1-\alpha$.  We would reject the parameter point $\theta$ if the integral of the probability of $t$ over points more extreme than $t_0$ is less than $1-\alpha$.  This is the equivalent of asking, "Does the measured value $t_0$ fall inside a window of size $\alpha$" (assuming that window corresponds to the region of data that is not considered extreme).  This region will correspond to the slice of the Confidence Band if the band is defined with an ordering principle that matches the definition of "extreme" used in the p-value test.

For example, if we create one-sided confidence intervals (starting from $-\infty$), that will be the equivalent of performing a 1-sided p-value test on all possible values of the parameter given some measured dataset.



<!--Let's consider a more complicated scenario.  Instead of considering two discrete hypotheses, we consider a family of hypotheses parameterized by a single variable.-->

<!--Sometimes, in this case, it is instructive to consider a single value of this variable to represent the null hypothesis and for all other points to represent a family of alternative hypotheses.  Depending on the problem, there may not actually be a null hypothesis, in which case all values of the parameter can be considered on common grounds.-->  

<!--
We imagine that we have a model which contains exactly one (unknown) parameter, and we further assume that SOME value in the range of that parameter makes our model the "true" model of the system we attempting to describe.

The question we then want to answer is, "For a given measured dataset, what is the set of points of the parameter which are supported by the data (or, conversely, which points are rejected by the data)?"

The typical frequentist method for addressing this problem is by calculating what is known as a "Confidence Interval".  We will discuss what this means and how to calculate it in some detail.

Before doing so, I'll note that a confidence interval is only an example of one thing that a person *could* do when faced with this scenario; it is not be-all-and-end-all thing that **can** be done.  It is a procedure, motivate by statistical intuition, that can be a useful took when thinking about a problem or making a decision.  But how one chooses to use data or what one wants to calculate all depend on one's purposes, the level of rigor necessary, and one's philosophy.  For now, let's assume that calculating a confidence interval is what we'd like to do here.
-->
<!--
https://indico.cern.ch/event/117033/contributions/1327622/attachments/55727/80175/Cranmer_L3.pdf
-->

## Calculating Intervals

The above procedure required on being able to do the following:

- Determine the distribution $p(t | \theta)$ for all values of $\theta$
- Integrate that distribution and find values $[a, b]$ such that the integral of that distribution sums to $\alpha$

If $\theta$ is a continuous parameter, this may seem to be a daunting task.  One could calculate this in a "brute-force" way by picking discrete values of $\theta$ and, for each value in this grid, generating values of x using the model $p(x | \theta)$ and then building up a distribution for $p(t | \theta)$.  One could then use computational techniques to integrate this distribution and obtain windows $[a, b]$ for each value of $\theta$, which would then be inverted to form confidence intervals.

Thankfully, there are a number of examples that have properties which allows one to calculate a confidence interval without resorting to a brute force procedure.  For example, if can choose a test statistic $t(x, \theta)$ such that the distribution $p(t(x, \theta) | \theta)$ is independent of $\theta$, then one does not need to pick discrete points in $\theta$ and generate intervals $[a, b]$ separately for each point.  One can do this once since the distribution $p(t(x, \theta) | \theta)$ and therefore the intervals $[a, b]$ are independent of $\theta$.  Further, if one can analytically integrate $p(t(x, \theta) | \theta)$ (or at least leverage well-studied lookup tables), then one doesn't need to perform manual integrals oneself.  Examples that satisfy this criteria are therefore much simpler to use.  In fact, MOST examples of confidence intervals that appear in textbooks have this property, which is nice, but I find that it hides the more general procedure that one needs to take to calculate confidence intervals for arbitrary models.

<!--
In the above procedure, iterated over small steps in our parameter to create the confidence band in a "brute force" fashion.  However, for a small subset of problems, the confidence band can be calculated exactly because the probability distribution can be handled analytically.

Given a probability density function $p(x | \theta)$, the procedure for generating a confidence interval of size $\alpha$ is:

- Find $C_L(\theta)$ and $C_U(\theta)$ such that the probability of $C_L(\theta) < x < C_U(\theta)$ is equal to  $\alpha$. This is typically done by integrating over the known pdf $p(g | \theta)$.
- Invert this inequality to find: $x^{-1}(C_L(\alpha)) < \theta < x^{-1}(C_U(\alpha))$
- The confidence interval is then given by $[x^{-1}(C_L(\alpha)), x^{-1}(C_U(\alpha))]$.

The inversion above is made simpler when $C_L(\alpha)$ is independent of x.  

The gaussian distribution is an example of one for which analytic confidence intervals can be calculated.  This plus the fact that it commonly occurs in a wide range of problems makes it very useful and important to understand.
-->


## Gaussian Example

As a simple but useful example, let's calculate confidence intervals for the parameter $\mu$ of a 1-d gaussian distribution (assuming that $\sigma$ is known and fixed).

<!--
The pdf of the gaussian distribution is given by:

$$
pdf(x | \mu, \sigma) = \frac{1}{\sqrt{2\sigma^2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} 
$$

We here assume that $\sigma$ is known or "fixed".
-->

To start, we need to determine our test statistic and our ordering rule.  For the simple 1-d case, it makes sense to simply take the value of $x$ as our test statistic: $t(x) = x$.  And, since this PDF is symmetric around $\mu$, it seems reasonable to choose confidence intervals that are centered around $\mu=x$.  This is also equivalent of picking confidence intervals of the minimum width (by including the highest-values of the likelihood first).

We then have to find a window $[a, b]$ in x, for every value of $\mu$, such that:

$$
\int_{a(\mu)}^{b(\mu)} gauss(x|\mu, \sigma) dx = \alpha
$$

Since we want the interval $[a, b]$ to be symmetric about $x=\mu$, we can re-write this as the following:

$$
\int_{\mu-\delta(\mu)}^{\mu+\delta(\mu)} gauss(x|\mu, \sigma) dx = \alpha
$$

where we assume the general case that we will need a different value of $\delta$ for every possible value of $\mu$.  The integral of a gaussian is a well-studied quantity, and therefore we can re-write the integral and leverage terms of well-known error function.  Let's assume that:

$$
\delta(\mu) = \Delta - \mu
$$

with $\Delta$ an unknown constant and perform a change of variables:

$$
m = \frac{(x - \mu)}{\sigma}
$$

giving us

$$
\int_{-\Delta}^{\Delta} gauss(m|0, 1) dm = \alpha
$$

The dependence of $\mu$ has dropped out, leaving us with the equation

$$
\text{erf}(\Delta) - \text{erf}(- \Delta) = \alpha
$$

which we can invert to get:

$$
\Delta = \sqrt{2}\text{erf}^{-1}(\alpha)
$$

Our confidence interval is therefore:

$$
[x - \sqrt{2}{erf}^{-1}(\alpha)\sigma, x + \sqrt{2}{erf}^{-1}(\alpha)\sigma]
$$

The key to being able to calculate this analytically was that the dependence of $\mu$ dropped out after a well-chosen change of variables.  In fact, we could have saved ourselves a lot of trouble had we defined our test statistic from the beginning as being:

$$
t(x) = \frac{x - \mu}{\sigma}
$$

since we already know that the distribution of this variable is independent of both $\mu$ and $\sigma$.  This emphasizes an important point: choosing the right test statistic can make a confidence interval calculation much easier.


<!--
http://mathworld.wolfram.com/ConfidenceInterval.html

[7] J. Neyman. Outline of a theory of statistical estimation based on the classical theory of probability.
Phil. Trans. Royal Soc. London, Series A, 236, 1937.
-->

<!--
Our confidence interval is then defined as: ${\mu: 

In this case, the confidence interval, for a measured value of x, would go from $[x-\delta(x), x+\delta(x)]$.  We just need to solve for $\delta(x)$.  The solution comes from using the error function.  This example turns out to be simple because delta ends up being a constant, independent of the measured value of x (this can be understood since the underlying pdf as well as our confidence intervals are symmetric under translations of x and $\mu$).

This means that if you measure a value of x from a gaussian distribution, your confidence interval is given by:

$$
[x - \sqrt{2}erf^{-1}(\alpha)\sigma, x + \sqrt{2}erf^{-1}(\alpha)\sigma]
$$

(Note that this problem is concerned with a single measurement x that is gaussian distributed with mean $\mu$.  We will later talk about building confidence intervals for the mean from n measurements from a single gaussian distribution).

This is a remarkable result: It means that I can easily build confidence intervals for gaussian distributions, simply by consulting a look-up table or by using a computer.
-->


<!--

## Example: Gaussian Distribution

Let's start with the simple example of a gaussian distribution and determine it's confidence interval.  It will turn out that this solution is extremely useful, as gaussian distributions appear often in nature due to the central limit theorem and that many distributions can, under certain conditions, be approximated as a gaussian distribution.

We start by assuming that we know our model is a gaussian distribution with known-and-fixed standard deviation $\sigma$ but an unknown mean $\mu$.  We are running an experiment to measure the mean.  In this experiment, we draw N points from the gaussian to give us the dataset $\{x\} = \{x1, x2, ..., x_N\}$.

The question then becomes: "Given this measured data, what can we learn about the true mean of our model, $\mu$?"

We can measure the mean of our data $\{x\}$, which we will name $\hat{\mu}$, but it's not immediately clear how this relates to the true mean $\mu$.  We would expect that these would be close to each other, so in a very loose sense, measuring $\hat{\mu}$ gives us a "ballpark" estimation of the true mean $\mu$.  Depending on one's purposes, this may be good enough.  If one isn't looking for statistical exactness or rigor, measuring the mean of a dataset and assuming it's "pretty close" to the true mean is certainly a fine thing to do.

But let's take our inference further and see what rigorous statements we can say about the parameter $\mu$.  At this point, the typical frequentist thing to do is to calculate a confidence interval, which we will do here.  I'll note that this is only an example of one thing that a person *could* do when faced with this data, and not the be-all-and-end-all thing that **can** be done.  Again, how one chooses to use data or what one wants to calculate all depend on one's purposes, the level of rigor necessary, and one's philosophy.  But, for now, let's assume that calculating a confidence interval is what we'd like to do here.

So, how do we calculate it in this gaussian example?  Recall that a confidence interval is not just a single interval $[min, max]$, but instead a procedure for calculating a $[min, max]$ set **given** some measured data.  Every possible dataset has a corresponding confidence interval on the parameter $\mu$, and the many intervals calculated on those hypothetical datasets must contain the true mean, $\mu_{true}$ with fraction $\alpha$ (where $\alpha$ is the "size" of the interval we're interested in, for example 95%).  

It isn't immediately clear how to translate the definition of a confidence interval into an actual calculation.  The definition is more of a description of the properties that an interval must have and not a prescription of how to create an interval with such properties.  Let's walk through how to actually translate this description into an actual interval.

-->

<!--

### Procedure 1: Brute Force

To me, the simplest way conceptually to calculate a confidence interval is using the "brute force" method of generating fake data using the statistical model for different possible values of $\mu$ and calculating the sample mean, $\hat{\mu}$ for each "fake" dataset.  By doing this, we can create a distribution of $\hat{\mu}$ as a function of $\mu$ and we can use that to approximate a probability distribution: $p(\hat{\mu} | \mu)$ (for example, by using a sufficiently granular histogram distribution or possibly by leveraging a kernel method).

How does generating this distribution help us to create the confidence interval?  We know that the true value of $\mu$, $\mu_{true}$, is some fixed number, for example $\mu_{true} = 1.2234$.  Therefore, if we are building a 95% confidence interval, we need to construct an interval on our fake data such that 95% of the intervals contain 1.2234.  More generally, we need to show that, for EVERY possible value of $\mu$, our procedure will generate confidence intervals that contain $\mu$ 95% of the time.

Using our "brute-forced" distribution, we will attempt to do this by construction.  We do this with the following procedure:

- Scan over values of $\mu$ and, for each value, generate fake data to build a distribution of our sample mean, $\hat{\mu}$.
- For each value of $\mu$, using that distribution, find a window of $\hat{\mu}$ whose total probability given $\mu$% is $\alpha$ (this is a valid statement to make in the frequentist framework since it describes the probability of data, $\hat{\mu}$, based on a model, summarized by $\mu$). <! --  We then find an interval in that distribution of size $\alpha$.  In other words, for a given value of $\mu$, the value of $\hat{\mu}$ will be in THAT interval with probability $\alpha$. -- >  Thus, for each value of $\mu$, we have built a window of $\hat{\mu}$.
- For the measured value of $\hat{\mu}$, find all values of $\mu$ whose window, as defined above, contains that measured value of $\hat{\mu}$.
- The set of all such values of $\mu$ is the confidence interval of $\mu$ for this particular value of $\hat{\mu}.  

Why does this work?  Why does an interval, defined in this way, have the properties of the confidence interval that we desire (namely that it contains the true value of $\mu$ with probability $\alpha$)?

Well, we start with the statement that here is only one TRUE value of $\mu$.  It is unknown to the person performing the experiment, but it exists.  For that fixed value of $\mu$, there will be a distribution of $\ht{\mu}$ generated (and we will measure a single random variable from that distribution when we perform the experiment).  

By tautology, there is a 95% change that the value of $\hat{\mu}$ that we draw will be in a 95% interval of the distribution of $\hat{\mu}$ given $\mu$.  There are two cases to example:

- Case 1: Given our true $\mu$, the value of $\hat{\mu}$ that we draw **IS** in that interval.  In this case, when the experimenter builds their confidence interval, it will contain the true value of $\mu$, since the true $\mu$ will be one of the $\mu$ values whose 95% confidence window contains $\hat{\mu}$
- Case 2: Given our true $\mu$, the value of $\hat{\mu}$ that we draw **IS NOT** in that interval.  Therefore, by the same logic, the experimenter's confidence interval will NOT contain the true value of $\mu$, since the measured value of $\hat{\mu}$ is outside of the 95% window of $\hat{\mu}$ given $\mu$.

And, as described, we know that case 1 occurs 95% of the time and case 2 5% of the time.  Therefore, we have proven that a confidence interval, as described above, will have the properties that we desire.



### Procedure 2: Exact Distribution

Since the gaussian example is a simple case, we can find the solution without resorting to brute force.  We used sampling to determine the distribution of $\hat{\mu}$ as a function of $\mu$.  But, for a Gaussian, we can find this distribution analytically.  It is given by:

$$
p(\hat{\mu} | \mu) = gauss(\hat{\mu} | \mu, \frac{\sigma}{\sqrt{N}})
$$

And since we have formulas/tables for taking the integrals of the gaussian, we can directly look up a 95% window for a given $\mu$.  For example, if we want a window of size $\alpha$, we know that the range of $\hat{\mu}$ in that window is given by:

$$
-1.96 < \frac {\hat{\mu} - \mu} {\sigma/\sqrt{N}} < 1.96
$$

(Knowing this formula is what allows us to shortcut past having to sample the distribution as we did above).

Let's say that we then measure a specific quantity $\hat{\mu}_{meas}$.  Following our procedure in the brute force example, we need to figure out which values of $\mu$ have a window that contains $\hat{\mu}_{meas}$.  In other words, we need to find all values of $\mu$ such that $-1.96 < \frac {\hat{\mu} - \mu} {\sigma/\sqrt{N}} < 1.96$.

We can do this by algebraically manipulating the inequality.  One can transform it to be:

$$
\hat{\mu} - 1.96\frac{\sigma}{\sqrt{n}} < \mu < \hat{\mu} + 1.96\frac{\sigma}{\sqrt{n}}
$$

To reiterate, this inequality gives us the set of all values of $\mu$ such that a given value of $\hat{\mu}$ is in the 95% probability window of $p(\hat{\mu} | \mu)$.  From this inequality, one can simply read off the confidence interval: Just plug in the measured value of $\hat{\mu}$ to obtain the upper and lower bounds on the confidence interval of $\mu$.  And, as demonstrated in the brute force example, we know that 95% of confidence intervals generated this way (across all hypothetical datasets) will contain $\mu_{true}$.

-->

<!--
  It is sufficient to pick an arbitrary value of $\mu$ and show that the confidence intervals we generate contain the $\,mu$ 95% of the time.  Here's how: For our measured value of $\hat{\mu}$, we will find the distribution of $\mu$ and create an interval that contains 95% of the values of $\mu$ (or whatever $\alpha$ is.  The next step is to convince you that this procedure will result in 95% of confidence intervals containing the true mean $\mu$.

The fraction of confidence intervals that contain the true mean $\mu$ is given by:

$$
f_{\text{contains }\mu} = \sum_{\hat{\mu}} prob(\hat{\mu} | \mu) * I_{interval(\hat{\mu}) \text{ contains } \mu}
$$

where $I_{interval(\hat{\mu}) \text{ contains } \mu}$ is an indicator function whose value is 1 when the confidence interval created for the measured value $\hat{\mu}$ contains the true mean $\mu$ and 0 otherwise.
-->

<!--
## Generalizing

Let's try to generalize what we did above for a general probability distribution.  For now, we'll require that it has only one unknown parameter (just as the only unknown parameter of the gaussian example was $\mu$).  We'll later discuss how to handle multiple unknown parameters.

In our example, we have a probability distribution function:

$P(x | \theta)$

We also have a measured dataset $\{x\} = \{x1, x2, ..., xn\}$ and a function $g(x1, x2, ..., xn, \theta)$ that depends on both the data and the parameter we want to measure (which in the gaussian example, $g(\vec{x}, \mu) =  \frac{\hat{\mu} - \mu}{\sigma / \sqrt{N}}$).

To calculate the confidence interval, we have two possible procedures, one using brute-force and one using analytic inversion.

### Brute force

- For each value of $\theta$, generate many datasets.  For each value of $\theta$ and for each dataset generated from that value, calculate $g = g(x, \theta)$ and build up a distribution $p(g | \theta)$.
- Find a window in each such distribution that contains $\alpha$% of the total probability
- Given the measured data, $\vec{x}$, find all parameters $\theta$ such that $g(\vec{x}, \theta)$ is in the $\alpha$-sized window for that value of $\theta$.  Those values form the confidence interval of size $\alpha$.

### Analytic

Assume that we have an analytic formula for $p(g | \theta)$, and further assume that we can invert this formula:

- Find $C_L(\alpha)$ and $C_U(\alpha)$ such that the probability of $C_L(\alpha) < g(x, \theta) < C_U(\alpha)$ is equal to  $\alpha$. This is typically done by integrating over the known pdf $p(g | \theta)$.
- Invert this inequality to find: $g^{-1}(C_L(\alpha)) < \theta < g^{-1}(C_U(\alpha))$
- The confidence interval is then given by $[g^{-1}(C_L(\alpha)), g^{-1}(C_U(\alpha))]$.

Note that this procedure makes a strong assumption: $C_L(\alpha)$ and $C_U(\alpha)$ must not be functions of $\theta$.  (In the gaussian example, $C_L(\alpha) = -1.96$ and $C_U(\alpha) = 1.96$, which are independent of $\mu$.  This was because we constructed the function $\frac{\hat{\mu} - \mu}{\sigma / \sqrt{N}}$ to be independent of $\mu$, as subtracting $\mu$ in the equation cancels out the dependence of $\mu$ in $\hat{\mu}$).

"Whatever the true value is, it will produce data within the band 95% of the time..."


### Discussion

The procedure outlined above, where we scan over every possible value of $\theta$ and use the distribution of the data given that value of $\theta$ to build a confidence interval, is known as the Neyman Construction.  An important note is that the problem that the examples we've looked at only have a single parameter for which we're interested in calculating confidence intervals, and there are no other free parameters in the model (we assume that other parameters are both known and fixed).


ORDERING RULE

What is a good choice of region?  Want to maximize "power".

LIKELIHOOD FUNCTION GAUSSIAN APPROXIMATION

RELATIONSHIP TO HYPOTHESIS TESTING

Notes:
-->

### Test Statistics

<!--
One can generalize the above approach by considering what is known as a "test statistic".  A test statistic is a quantity that can be used in place of the data x in the above arguments.  One can simply re-run all of the above arguments with the replacement of $x -> f(x)$ with f being any function of the data.  Distributions of x will be replaced with distributions of f(x), and the rest of the statistical argument will remain the same.

However, a test statistic may also be a function of the parameter of interest, $\theta$.  We will here show how to generate confidence intervals using such a test statistic.  Consider the test statistic $t = t(x, \theta)$.  $t$ is a function of the data and of our parameter (note that it is not a probability distribution, it is an arbitrary function that evaluates to a real number).  How can we use this to generate confidence intervals?

The procedure we followed using the raw data was to:
- Consider each point in the parameter space, $\theta_0$
- Generate the distribution of the data at that point: $p(x | \theta_0)$
- Create an "acceptance region" of size $\alpha$ in that distribution
- Measure an experimental value of x
- The confidence interval is the set of all values of $\theta$ whose acceptance region contains the measured value x.

Using a test statistic, we can follow an analogous procedure:
- Consider each point in the parameter space, $\theta_0$
- Given the model and the value $\theta=\theta_0$, generate datasets of {x_1, x_2, ...x_n}.  Calculate {t(x_1, \theta_0), t(x_2, \theta_0), ...,  t(x_n, \theta_0)}.  Use this to generate the distribution $p(t(x, \theta_0) | \theta=\theta_0)$.
- OR, if one is lucky enough, use an analytic formula for the distribution of the test statistic (at evaluated with $\theta=\theta_0$).
- Using that distribution, pick an acceptance region of size $\alpha$ in the distribution of $t(x, \theta=\theta_0)$.  Do this for every value of $\theta$.
- Measure the data x
- For each value of $\theta$, calculate $t(x, \theta)$
- The confidence interval consists of all values of $\theta=\theta_0$ such that $t(x, \theta_0)$ is in the acceptance region.

This method requires obtaining a distribution for the test statistic evalauted at each point $\theta=\thteta_0$ GIVEN the assumption that the true value of $\theta$ is $\theta_0$.  The potentially confusing point here is that the test statistic itself varies at each test point $\theta_0$ (and therefore it's distribution may also vary as a function of $\theta$).  And, as a result, we must calculate the test statistic at every value in our parameter space to invert it.

But it's easy to show that this procedure does indeed generate confidence intervals.  There is one true value of theta, $\theta_{true$}.  We simply need to show thtat $\theta_{true}$ falls in our confidence region $\alpha$ of the time.  But, by construction, $t(x, \theta_{true})$ will fall in the acceptance region of $\theta=\theta_{true}$ a fraction of the time equal to $\alpha$.  Therefore, when we invert the acceptance region, $\theta=\theta_{true}$ will fall in our confidence interval at a rate of $\alpha$.

Thus, we can generalize our approach by considering test statistics that may depend on the parameter we are interested in.  This is valuable in part because we may be able to generate distributions of these test statistics easier than we can generate distributions of the draw data.  In addition, by varying them as a function of our parameter of interest, can can make confidence intervals that are more powerful (since the test statistic can be chosen for it's power for each value of $\theta_0$ separately).

As before, we can interpret this as performing a p-value at each point in the parameter space of $\theta$, and creating a confidence interval as the set of all points that are not rejected by that p-value test.  By using a test statistic, we can consider the distribution of a different value at each point in parameter space to perform this $p-value$ test.
-->

As seen above, an important step in the building of confidence intervals is the choice of the test statistic.  A test statistic is a value can be calculated as a function of a given dataset and a given model (or model parameters) associated with that dataset.  The definition of a test statistic may be defined in terms of assumed values of parameters.  <!--Some places define a statistic as a function of the data only which cannot depend on the parameter of interest. But, a--> As we've seen above in the Gaussian example, defining a function in terms of the parameter of interest can lead to it having useful properties, specifically that it's distribution is independent of the parameter of interest.  While some references may present the definition of a test statistic as being defined only in terms of data, doing so seems to contradict the clearly useful technique of including assumed values of parameters of interest, so we will here not attempt to present the definition so strictly. 

<!--
  Some references call this  While  Some references distinguish this as a "quantity" and not a statistic.  We will here adopt a looser language: A test statistic is just a of the data and possibly model parameters that is useful in performing inference).
-->

<!--A test statistic is used as the starting point of a statistical test.  One typically performs a test by considering a model, defining a test statistic for that model, measuring data, calculating the test statistic for that model (or model parameters) and the measured data, and comparing that value to the known distribution of the test statistic (given the assumed model).-->

A test statistic is useful for inferring the value of a parameter of interest if:

- It can be easily calculated
- Its distribution (given a fixed model or model parameters) is known
- It or its distribution must depend on the parameter of interest
- Its distribution does not depend on any unknown (nuisance) parameters

<!--
Note that a test statistic may or may not be defined in terms of the parameter of interest.  For example, we found above that a good test statistic to infer the value of $\mu$ from a gaussian distribution was:

$$
t(x) = \frac{(x - \mu)}{\sigma}
$$

In this example, the test statistic is a function of the parameter of interest $\mu$ (we assumed that we knew the fixed value of $\sigma$, so the fact that it depends on this as well is irrelevant).
-->

<!--
As described above, we want the distribution of the test statistic to depend on the parameter of interest.  However, the calculation of the test statistic may or may not depend on the parameter of interest.  Say that we have a test statistic t and a probability distribution function pdf for t under a given model, and we are interested in a parameter $\mu$.  We want pdf(t) = pdf(t | $\mu$).  However it may be the case that t itself depends on mu: $t = t(\vec{x}, \mu)$ or that t is independent of the parameter: $t = t(\vec{x})$.
-->

For a given model, there are many possible test statistics.  So, how should one go about picking the "best" test statistic, or what does it even mean for a test statistic to be good?  <!--When using a test statistic for inference a requirement is that the test statistic be a function of the parameter of interest (after all, if the distribution of the test statistic didn't depend on the parameter of interest, than measuring the test statistic wouldn't tell us anything about that parameter).-->  Intuitively, a test statistic is good if it's distribution under different values of the parameter(s) of interest varies dramatically.  This allows one to use the test statistic to determine which model is most likely the "true" model (again, this loose language will be made more formal later).

There are a number of types of tests statistics which have useful properties for inference.

A "pivotal quantity" is a test statistic whose distribution does not depend on the parameter of interest.  As noted above, the most common example is for a gaussian distribution, where the distribution of the quantity:

$$
q(x, \mu) = \frac{\bar{x} - \mu}{\sigma}
$$ 

is $gauss(q, 0, 1)$ and does not depend on $\mu$.  As exemplified above, if one can define a pivotal quantity in terms of a parameter of interest (such that the pivotal quantity is defined  in terms of the parameter of interest but whose distribution is independent of the parameter of interest), then calculating confidence intervals is easy.


A "sufficient statistic" is a test statistic that, for the purpose of inferring a given parameter, contains as much information as the raw data.  Specifically, a statistic $t$ is sufficient if, given fixed values of $t$ and the parameter of interest $\mu$, the distribution of the data $x$ does not depend on $\mu$.  A statistic is sufficient if and only if the likelihood can be written as:

$$
L(x | \mu) = h(x)g(t(x), \mu) 
$$

where x is the data, $\mu$ is the parameter of interest, and $t(x)$ is our test statistic.  This means that the part of the likelihood that depends on the parameter of interest $\mu$ only depends on x via $t(x)$.  Intuitively, the $h(x)$ term gives us no information about $\mu$, so we can ignore it.  In other words, for the purpose of performing inference on the $\mu$, one does not lose any information by summarizing the data with the value of the test statistic $t$.

As an example, consider the gaussian distribution for a set of iid measurements $x_1...x_i$.  We can write the likelihood as:

$$
L(x_1...x_i | \mu, \sigma) = \prod gauss(x_i | \mu, \sigma)
$$

but we can also write it as:

$$
L(x_1...x_i | \mu, \sigma) = c e^{-\frac{n}{2}(\bar{x} - \mu)^2} e^{-\frac{n}{2}\sum(x_i - \bar{x})}
$$

If our parameter of interest is $\mu$, then we can see that only the first exponential depends on $\mu$, and it depends on the data $x$ only via $t = \bar{x}$.  Therefore, if we are performing inference on  $\mu$, it is sufficient to know only $\bar{x}$.

More generally, when inferring parameters $\mu_1...\mu_i$, if I can write the likelihood as:

$$
L(x | \mu_1...\mu_i) = h(x) g(\mu_1...\mu_i, t_1(x)...t_i(x))
$$

then the set ${t_1...t_i}$ are sufficient statistics for inferring $\mu_1...\mu_i$.

In contrast, an "ancillary statistic" when considering a parameter $\mu$ is a function of the data whose distribution does not depend on the parameter $\mu$.  In other words, measuring the value of an ancillary statistic doesn't give you any power to constrain the true value of the parameter $\mu$.

<!--

There is another property of statistics called "completeness".  We will not discuss this further except to mention a fact called Basu's theorem that states that a sufficient AND complete statistic for a parameter $\mu$ is independent of any ancillary statistic for $\mu$.
-->
<!--

http://math.arizona.edu/~tgk/466/sufficient.pdf

https://onlinecourses.science.psu.edu/stat414/node/285

http://www.stat.umn.edu/geyer/old03/5102/notes/ci.pdf

https://stats.stackexchange.com/questions/203520/can-a-statistic-depend-on-a-parameter
-->


## Approximate Confidence Intervals


As demonstrated above, confidence intervals for some models can be calculated exactly, as the model's pdf can be inverted analytically (or, at least the inversion can be arbitrarily approximated by a computer or a table).  However, this is not the case for many real-world problems.  Fortunately, there is a useful approximation that allows one to calculate approximate confidence intervals for a wide range of problems.


### Approximate Confidence Intervals of Maximum Likelihood Estimators (Wald Tests)

When creating a confidence interval for a maximum likelihood estimator, one can obtain an approximate interval by using the asymptotic distribution of MLEs.

Recall that, for a pdf representing iid data, the MLE of a parameter, for large N, is approximately gaussian distributed:

$$
p(\hat{\theta} | \theta) \sim gauss(\hat{\theta} | \theta, \sigma_\theta)
$$

where $\sigma_\theta$ is related to the Fischer Information of the true distribution:

$$
\sigma_\theta = \sqrt{\frac{1}{FI(\theta)}}
$$

If we knew $FI(\theta)$, then we could use our knowledge of the gaussian distribution to create asymptotically accurate confidence intervals.

In most cases, one doesn't know the true distribution, and therefore one cannot exactly calculate $FI(\theta)$.  One can instead calculate the Fisher information of the estimated distribution, which is the one calculated using the estimated parameters: $FI(\hat{\theta})$.

This can then be compared to a gaussian distribution to obtain confidence intervals.  Often, instead considers the squared quantity: $(\hat{\theta} - \theta)^2$.  Since  $\hat{\theta} - \theta$ approximately follows a gaussian, $(\hat{\theta} - \theta)^2$ will follow a Chi-Squared distribution with 1 degree of freedom.  Often, one uses this Chi-Squared distribution to perform a Wald test and obtain confidence intervals.

In general, the Wald test uses a rough approximation and often yields inaccurate results.  In particular, if one uses an approximation to the variance of the MLE estimator, the rate of convergence of the approximation will decrease, yielding a less accurate result.  However, the simplicity of the test, and the fact that it can be quickly calculated, makes it commonly used.


### Approximation via Wilks Theorem

Another approximation that is commonly used to obtain confidence intervals a result known as Wilks Theorem to obtain an asymptotic distribution for a quantity known as the likelihood ratio.  Statistical tests using this result are often referred to as Likelihood Ratio tests.

<!--
We showed above that one can approximate the distribution of a MLE using the Fisher information from the likelihood

Often, however, one may not have an analytic formula for the likelihood function.  This is often the case when the likelihood is very complicated and is represented only as a function in a computer program.  One is able to calculate it for any input values of the data or the parameters, but one cannot write it down or readily take derivatives analytically.  Therefore, the above approximations will not work.

However, one can make use of another theorem which enables the calculation of approximate confidence intervals in the "asymptotic" case of a compound likelihood where n grows large.
-->

Consider the likelihood of data of a single parameter, $L(x | \theta)$ (the data $x$ may be multi dimensional or arbitrarily complex).  As above, we define $\hat{\theta}$ as the value of $\theta$ that maximizes the likelihood function.  We now define the likelihood ratio as the following function:

$$
LR(\theta) = \frac {L(x | \theta)} {L(x | \hat{\theta})}
$$

It can be thought of as the ratio between the likelihood's maximum value and it's value at any point $\theta$.  We will also defined the negative log likelihood ratio as:

$$
nllr(\theta) = -log(\frac {L(x | \theta)} {L(x | \hat{\theta})})
$$

In the case of a likelihood describing N iid samples (with large N), a result known as Wilks' Theorem tells us that the distribution of the $nllr$ evaluated at the true (unknown) value of $\theta=\theta_{true}$ (and assuming that the model associated with  $\theta_{true}$ is true) follows a Chi-Squared distribution:

$$
p(nllr(\theta_{\text{true}})) \sim \chi^2_m(2*nllr(\theta _{\text{true}}))
$$

where $m$, the number of free parameters, here is equal to 1 because $\theta$ is the only unknown parameter.  In other words, if you assume that some value of $\theta_{true}$, use your model to generate data with the distribution $p(x | \theta_{true})$, and calculate $nllr(x | \theta_{true})$ on each of those datasets, the values ${nllr(x_1 | \theta_{true}), nllr(x_2 | \theta_{true})...}$ will be distributed as $\chi^2_1$.  Note that this Chi-Squared distribution does NOT depend on the value of $\theta_{true}$ that we chose (this remarkable result is why Wilks theorem is useful).

Thus, we can use the function $t = 2*nllr(x, \theta)$ as a test statistic to generate confidence intervals on $\theta$.  The fact that the distribution of the test statistic $nllr(x, \theta=\theta_{true})$ under the assumption that $\theta=\theta_{true}$ doesn't depend on the value of $\theta_{true}$ makes $nllr(x, \theta)$ a pivotal quantity (asymptotically).  Therefore, we can use the $\chi^2$ distribution directly to lookup confidence intervals using the following procedure:

- Pick a size $\alpha$
- Using the $\chi^2$ distribution, find the values $[0, nllr_{\text{critical}}$ such that$\int_0^{nllr_{\text{critical}}}p(nllr)d(nllr) = \alpha$
- Invert $nllr(\theta) <  nllr_{\text{critical}}$ to get all values of $\theta$ for which the probability of $nllr(\theta) > \alpha$

<!--
calculating the confidence intervals easier (not that $nll(x, \theta)$ DOES depend on $\theta$, by construction, but it's distribution doesn't).  The procedure is therefore to:

- Calculate $nll(x, \theta)$
- Pick a value of $\alpha$
- Use the CDF of the chi-squared distribution to find the value of the nll such that $\int_0^{nll_{\text{critical}}}p(nll)d(nll) = \alpha$
- Invert $nll(\theta) <  nll_{\text{critical}}$ to get all values of $\theta$ for which the probability of $nll(\theta) > \alpha$
-->

These values of $\theta$ form the confidence region.  This works if one can invert the $nllr$ to find the values of the parameter $\theta$ such that $nllr(\theta) =  nllr_{\text{critical}}$.  One can do this inversion analytically (if they know the functional form of $nllr(\theta)$).  Or, if one does not have access to the analytic form of $nllr$, or if it's not readily invertible, one can simply scan over values of $\theta$ until they find a $\theta_{\text{critical}}$ such that $nllr(\theta_{\text{critical}}) =  nllr_{\text{critical}}$.

This procedure leads to a nice trick.  Because $\int_0^2\chi^2(x)dx = 0.683$, we know the critical value of the test statistic for a 68.3% confidence interval is 1.0.  Therefore, the bounds of the confidence region are those values of $\theta$ for which

$$
t = 2*nllr = 2 \frac{log(x | \theta_{\text{critical}})}{log(x | \hat{\theta})} = 1.0
$$

Using the above, we can directly see that the critical value of $\theta$ for a 68.3% confidence interval is the one such that: $\frac{log(x | \theta_{\text{critical}})}{log(x | \hat{\theta})} = \frac{1}{2}$.  Thus, to find a 68.3% confidence interval for the parameter $\theta$, simply find the value of $\theta$ that maximizes $nllr$ (the center of the confidence interval), note $nllr_{max}$ at that point, and scan along values of $\theta$ until the value drops to half of the max.  That value is the boundary of the confidence interval.

An important point to note is that these intervals will be symmetric around the MLE, as they assume that the distribution of the MLE is a gaussian, which is a symmetric distribution.

<!--
https://arxiv.org/pdf/1007.1727v2.pdf

https://arxiv.org/pdf/1503.07622.pdf

S.S. Wilks. The large-sample distribution of the likelihood ratio for testing composite hypotheses.
Ann. Math. Statist., 9:60–2, 1938

https://indico.cern.ch/event/117033/contributions/1327622/attachments/55727/80175/Cranmer_L3.pdf

http://www.astro.princeton.edu/~strauss/AST303/bayesian_paper.pdf

https://books.google.com/books?id=jGUVmjGP9qkC&pg=PA51&lpg=PA51&dq=likelihood+gaussian+approximation&source=bl&ots=YbM-PRTW3R&sig=atiY_p4yo8O1fH55jPUffRbD0jI&hl=en&sa=X&ved=0ahUKEwi1l_3DxcLRAhWrllQKHQ2vDrE4ChDoAQghMAE#v=onepage&q=likelihood%20gaussian%20approximation&f=false

https://arxiv.org/pdf/physics/0311105v1.pdf

https://arxiv.org/pdf/physics/9711021.pdf

http://www2.econ.iastate.edu/classes/econ671/hallam/documents/Asymptotic_Dist.pdf

http://www.konstantinkashin.com/notes/stat/Maximum_Likelihood_Estimation.pdf

http://www.math.chalmers.se/Stat/Grundutb/CTH/mve300/1112/files/Lecture4/Lecture4.pdf

http://sites.stat.psu.edu/~sesa/stat504/Lecture/lec3_4up.pdf


*A (1 − α) confidence region can be defined simply as a collection of parameter values that would not be rejected by a Fisherian α level test, that is, a collection of parameter values that are consistent with the data as judged by an α level test.*

-->

### Approximations using the Profile Likelihood Ratio

Above, we used the Wilk's Theorem to generate confidence intervals using an asymptotic distribution of the likelihood ratio.  We did so in the case of a single parameter of interest $\theta$.  Often, however, one has a model of many parameters, all of which are unknown, but one may only be interested in obtaining confidence intervals of one of those parameters.  We refer to the single parameter that we'd like to perform inference on as the Parameter of Interest, and all other unknown parameters are called Nuisance Parameters.  We can write our likelihood in terms of these:

$$
L = L(x | \theta, \vec{\nu})
$$

where $x$ is our data, $\theta$ is our parameter of interest, and $\vec{\nu}$ represents our nuisance parameters.  We cannot directly use Wilks theorem above to obtain confidence intervals on $\theta$ if we don't know or assume the values of the nuisance parameters $\vec{\nu}$.  

The maximum likelihood estimators for this likelihood are denoted as $\hat{\theta}$ and $\hat{\vec{\nu}}$.  These represent the values of $\theta$ and $\vec{\nu}$ that simultaneously and unconditionally maximize $L$.  Imagine, instead, that we were to fix a value of $\theta$ to be $\theta_0$ but to then maximize the likelihood conditional on $\theta=\theta_0$.  The values of the nuisance parameter that maximize that form of the likelihood may be different from the values that maximize the unconditional likelihood.  We denote these as $\hat{\hat{\nu}}$.

Given that definition, we define a quantity known as the profile likelihood ratio as the following:

$$
\text{profile likelihood ratio}(\theta) = \lambda(\theta) = \frac{L(x | \theta, \hat{\hat{\nu}})} {L(x | \hat{\theta}, \hat{\nu})}
$$

In other words, we do the following:

- Find the global maximum of the likelihood across all parameters
- Fix $\theta$ to be some test value and find the values that maximize $\n$ given that test point
- Calculate the likelihood for the test $\theta$ and $\hat{\hat{\nu}}$, the values that maximize the likelihood over the nuisance parameters at the test point $\theta$
- Take the ratio of these two quantities.

When there are no nuisance parameters $\nu$, this simply reduces to the standard likelihood ratio.

An extension of Wilks' theorem states that the distribution of $-2$ times the log of the profile likelihood ratio, given that $\theta$ is the true value that generated the data in question, asymptotically converges to a Chi-Squared distribution:

$$
p(-2 log(\lambda(\theta)) | \theta_{\text{true}, \nu} = \theta)  \sim \chi^2_{s}
$$

or simply

$$
-2 log(\lambda(\theta)) \sim \chi^2_{s}
$$

where $s$ is the number of parameters of interest, here only 1, corresponding to $\theta$.  The important point is that the distribution of $\lambda$ is independent of the true values of the nuisance parameters.  Thus, the profile likelihood ratio is a pivotal quantity whose distribution we know (asymptotically).  Therefore, we can invert it to create confidence intervals on the parameter of interest.

This is a pretty remarkable result.  The likelihood in question could be arbitrarily complicated and contain many nuisance parameters, and yet (given enough data) we can find a distribution that depends only on the parameter of interest and that has a simple, well-studied analytic form.

In contrast to the Wald intervals above, the intervals obtained from the profile likelihood ratio may be asymmetric, depending on the actual form of the likelihood.  More generally, they will better respect the actual bounds of the likelihood (since they are not making a local-gaussian assumption).

<!--
### Bootstrapping

We need to assume that $p(\hat{mu} | \mu)$ is independent of mu.

http://www.stat.ucla.edu/~hqxu/stat105/pdf/ch08.pdf

-->



